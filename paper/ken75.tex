% This project is part of the Ken75 project.
% Copyright 2016 David W. Hogg (NYU) (MPIA) (Flatiron)

% # to-do
% - finish first draft
% - give it to friendlies for comments
% - pack it full of citations

% # style notes
% - Capitalize Hubble Time, Galactic Archaeology, Newtonian Gravity, and tha like.
% - Lighten up on the footnotes; not so earnest!

\documentclass[11pt, letterpaper]{article}

% definitions
\newcommand{\documentname}{\textsl{Note}}
\newcommand{\footnotename}[1]{\textsl{footnote}~\footnotemark[\ref{#1}]}

% spacings
\linespread{1.09}
\setlength{\parindent}{1.2\baselineskip}
\raggedbottom
\sloppy\sloppypar
\frenchspacing
\thispagestyle{empty}

\begin{document}

\section*{The state and future of Galactic Archaeology%
\footnote{This \documentname\ is loosely based on remarks I made at
  \textsl{2016 Elizabeth and Frederick White Research Conference on
    Galactic Archaeology and Stellar Physics: Understanding the
    origins of the Galaxy and its stellar content}, held in honor of
  Ken Freeman (ANU). The meeting took place in Canberra, 2016 November 21--25.\label{foot:conference}}}

\noindent
\textit{by} {David W. Hogg}%
\footnote{My affiliations are the \textsl{Center for Cosmology and
    Particle Physics} in the \textsl{Department of Physics} at \textsl{New York University}, the
  \textsl{Center for Data Science} at \textsl{New York University}, the
  \textsl{Flatiron Institute} in New York City, and the
  \textsl{Max-Planck-Institut f\"ur Astronomie} in Heidelberg. My email address
  is easy to find on the internets.
  
  This work
  was partially supported by the NSF (grant AST-1517237), NASA (grant
  NNX16AC70G), and the Moore--Sloan Data Science Environment at
  NYU. It is a pleasure to thank Andy Casey (Cambridge), Melissa Ness
  (MPIA), and Hans-Walter Rix (MPIA) for valuable comments.}

\paragraph{abstract:}
I unfairly summarize some of the very promising directions of research
into the formation, history, and dynamics of the Milky Way. I focus
especially on the idea of chemical tagging, or the identification of
stars that were formed at common star-formation events but which are
now spatially separated in the Galaxy. Chemical tagging has a
beautiful scaling with data volume; we learn much more as we observe
more stars. I then unfairly (but constructively) criticize the very
capable community working towards these goals. I make proposals for
how we ought to be using machine learning (carefully) and
probabilistic reasoning (we need new methods) to achieve our goals.  I
also strongly encourage the community to look to new modes of
observing: Spectroscopically trained photometry programs might do far
more than spectroscopy alone, and observations of nearby external
galaxies might straightforwardly and efficiently answer some direct
questions about our own Galaxy.

\section{What is Galactic Archaeology?}

The goal of Galactic Archaeology is to
use the stars that we see in the Milky Way right now (and possibly
also the dust and gas) to infer the past history of star formation,
mass assembly, accretion, and orbital evolution of the Milky Way. That
is, the field would be a complete success if we could show the Milky
Way as it was---in shape, kinematics, and chemical compositions---at
various stages in its past, back to the beginning of its formation
shortly after the Big Bang.

In Galactic Archaeology, we would like to ``run back the clock'' on
galaxy formation! In some sense this should be impossible: In a
nonlinear dynamical system, it is impossible to run the clock back
through many dynamical times accurately! However, in the case of the
Milky Way, we have many strong beliefs that can help us regularize or
constrain this inverse problem. One thing we believe is that stars
have as invariants their surface chemical abundances, from shortly
after formation until today. This invariance is not exact: There are
dredge-up and accretion processes that will make adjustments (more
about this below). But we believe that there is a lot of information
in surface abundances. Another thing we believe is that stars that
were born together---in the same molecular cloud, say---will have
identical or at least similar chemical abundances (more about this
below). Another is that the Milky Way must have formed from somehow
``typical'' initial conditions and grown by dynamics that are very
close to those described by the $\Lambda$CDM model of physical
cosmology.

Please do not take this last point to be an endorsement of the idea
that we know everything about the cosmological model, the dark sector,
and the initial conditions. We don't! Indeed, my own personal
motivation for pursuing Galactic Archaeology is to put dynamical
constraints on the cosmological model, the initial conditions, and the
physical properties of the dark matter. But $\Lambda$CDM is such a
successful theory for explaining so much data on so many scales, it
must be at least a \emph{good approximation} to the true theory of
structure formation in the Universe. That is, any theory that replaces
$\Lambda$CDM must make near-identical predictions on very large
scales, and only different-in-detail predictions at small scales, in
order to be a contender. So whatever the true (or truer) theory of
physical cosmology, $\Lambda$CDM must be a close approximation to it,
and will probably be used as a computational surrogate, in the same
way that Newtonian Gravity is used as a computational surrogate for
the truer theory of General Relativity. That is, if Galactic
Archaeology is supremely successful, we will replace $\Lambda$CDM with
a better theory, and cold dark matter with a more physically rich
dark-matter theory. But that theory will probably be similar to
$\Lambda$CDM in its predictions, and probably be much harder to
simulate or compute.

That brings up an important point for the state of the field and what
follows in this \documentname: The fundamental theory of cosmology is
a \emph{computational} theory, a theory that makes predictions only
after enormously complex and computationally expensive simulations
have been run. These simulations involve brutal approximations and are
always resolution-limited. How can we make precise inferences in this
context?  Much work on Galactic Archaeology makes only indirect---or
no---use of the theory of galaxy formation. However, the part that
\emph{does} make use of theory falls into two general camps (and, of
course, many investigators sit in both camps): In one camp, the
approach is to simulate in gory detail as many Milky-Way-like galaxies
as you can, as realistically as you can (and typical projects can
simulate 4 to 20 of them!), and look at the properties of our own
Milky Way in the context of the equivalent properties of these
simulated exemplars. That is important for building intuition, but
it doesn't answer quantitative questions, or not with great precision.

% The above and below paragraphs need citations out to relevant
% example papers.

In the other camp, the approach is to make analytic models (still
computational, but the computation is to solve equations within a
simple theory or a toy galaxy, not running a full-blown simulation)
that explain parts of the data, and in which true inference can
proceed. These models are usually regular (as in: no chaotic orbits)
and always simplistic (none of the phase-space complexity of a
$\Lambda$CDM simulation), but they permit parameter estimation and
hypothesis testing with all the precision that Bayes or frequentism
permits. There is a trade-off here between comparing the Milky Way to
our best beliefs (which are expressed by simulations) or to our most
tractable models (which permit precise measurements). This isn't a
resolved issue as of today. I will say more below.

Galactic Archaeology is a young field, but there are a few interesting
and tantalizing results... alpha on Fe and Fe on H as a function of
position; both different everywhere and the same everywhere!.. Is this
a contingent property of the Galaxy (event) or a fundamental property
of nucleosynthesis (attractor)?.. The chemical thick disk?

Star clusters are remarkably homogeneous (with exceptions). Globular
clusters less so, but also lower metallicity, so... This bodes well
for running back the clock...

Cold stellar streams and the hot Sagittarius stream and what they
might say about the Galaxy. Ultrafaints associated with the LMC and
SMC. Accretion in general...

Stellar ages coming accessible...

\section{What is chemical tagging?}

If stars work the way we think they do, then the surface chemical
abundances---the chemical abundances as measured by a stellar
spectrum---ought to change very little over a star's lifetime. There
are exceptions of course. Some elements can be dredged up from the
core. Accretion of exoplanets, asteroids, or interstellar dust can
affect stellar surfaces, and there might be other small effects. But
if this is even close to true---that most surface chemical abundances
are invariants\footnote{I distinguish the words ``invariant'' and
  ``conserved'', and recommend that we all do the same. An invariant
  quantity doesn't change with time. A conserved quantity is subject
  to a conservation law generated by some kind of symmetry (as
  momentum conservation is generated by translation
  invariance). Conservation does not imply invariance (in the case of
  momentum, there can be external forces). It is invariance that
  matters to us here.}---then every star is labeled with the
nucleosynthetic conditions of its birth.

Imagine against hope that the Milky Way has an integrable potential,
or that the majority of its orbits are regular. I don't have much
intuition here, except that the time-dependence of mass assembly, the
non-axisymmetry observed in the disk (CITE), the radial migration
that we expect therefrom (CITE), and $\Lambda$CDM substructure all
suggest to me that regular orbits are probably rare. But just for the
sake of argument, imagine that there are many regular orbits. Stars on
these regular orbits have three invariant actions, preserved from
birth. Every star is labeled with the dynamical conditions of its
birth.

The combined chemo-dynamical space---the space of chemical plus
dynamical tags---ought to be far more informative about the formation
and evolution of the Milky Way than either taken alone. This is a
statement, in a sense, of the goal of Galactic Archaeology.  And it
must be true to some extent in the case of chaotic potentials
too.\footnote{The Lyapunov Times in the halo, at least, can easily
  become comparable to the Hubble Time (CITE). In this case, although
  there aren't strictly invariant actions, there ought to be
  approximate surrogate invariants good for many Gyr.} It is
\emph{not} the specific meaning, however, of the name ``chemical
tagging'' as it was first coined (CITE).

The hope of chemical tagging is that we might be able to identify
pairs or groups of stars that literally were born together in the same
molecular cloud, using the chemical signature as a ``dog tag'' that
uniquely identifies the identity of its birth molecular cloud. That
is, chemical tagging is the idea that the chemical signature will be a
complex, unique (or close to unique; more about this below) hash of
location of origin in 3+1-dimensional space-time.\footnote{Presumably
  molecular clouds evolve with time, so even if a cloud produces many
  star-formation events, each of these events should be at least
  slightly different in chemical space. One molecular cloud traces out
  a world-line in 3+1-dimensional space as its chemical abundances
  evolve through nucleosynthesis, accretion, and winds.}  Thus stars
with common chemical signatures can be found to have origin at similar
space-time events, and stars with different chemical signatures at
different events.

In the ideal, non-parametric\footnote{I am using the word
  ``non-parametric'' in its true sense here. It describes the class of
  models whose size and complexity grows linearly with the data.}
chemical-tagging procedure would have the molecular clouds exist as
latent objects\footnote{HOGG DEFINE LATENT} in the model, revealed
only by the coincidence of chemical tags across stars. The na\"ive way
to think about it is the following: As each star gets measured, it
either gets assigned to a known birth event (known from previous
stellar observations), or else it gets assigned to a new birth event,
previously unknown (and now with one assigned star).

The exciting (to me) prospect of chemical tagging is that it could
provide most value exactly when the potential is \emph{not}
integrable; when stars are migrating radially and getting mixed.
It is exactly then that the discovery of stellar births becomes
difficult (or maybe impossible) from dynamical considerations alone;
chemistry could provide the missing data.

Chemical tagging only works by the na\"ive approach above in the case that we can
answer two hard questions, and, furthermore, that those two hard
questions give us answers of the kind we want. The two questions of
chemical tagging are the following: \textbf{(1)}~Given two stars that
were formed at the same birth event, how different can their detailed
chemical abundances be? and \textbf{(2)}~Given two stars that were
\emph{not} formed at the same birth event, how \emph{similar} can
their detailed chemical abundances be? The na\"ive approach to
chemical tagging only works if the answers to these two questions
don't overlap in bad ways.

Of course we aren't doomed if the answers come out bad; we just have
work harder. More on this below. For now, let's be optimistic, because
it makes the program easier to talk about. We will deal with the
pessimistic regime towards the end of this \documentname.

\section{The birthday paradox}

At the meeting at which I made (some of) these remarks,\footnote{See
  \footnotename{foot:conference}.} I challenged the principals in
various very, very large spectroscopic surveys (CITE AWAY) to explain
to me why, if we have 300,000 stars with excellent spectra, why we
need 500,000 more (let alone millions more).\footnote{I also
  acknowledged that I am guilty of helping and proposing such
  projects; I am part of the problem here.} What questions can be
answered with 800,000 stars that can't be answered with 300,000? 

Of course I myself do have an answer to this question. It is up to my
loyal reader whether the answer is worth the cost of these large
programs, which tie up world-class facilities for years at a time.  My
answer is that the present-day configuration-space layout of stars
that were formed together in common birth events is likely to be
(perhaps even \emph{known} to be) very dilute and complex. That means
that it might take one heck of a lot of well observed stars before we
start finding chemical-tagging matched pairs in large numbers. And the
scaling of discoveries with sample size is extremely good:

I am an afficionado of data-analysis situations where the scaling is
better than $\sqrt{n}$. That is, when can you take four times as much
telescope time and learn more than twice as much as you knew before?
Indeed, in some sense, you can see much of what I say from here on in
this \documentname\ as addressing this question, in one form or
another, as it applies to Galactic Archaeology... proper
motions... time-domain... exceedingly rare objects... qualitatively
new observation types!

Excitingly for me and for the field of Galactic Archaeology, chemical
tagging is one of these situations...

The paradox and what you can learn.

Numbers of stars; scaling.

\section{What are the biggest problems with this field?}

Story time!

So many spectra, so little understanding of chemical space, or anything else.

Spectroscopy and its discontents.

And looking only at the Milky Way!

Open science---and the lack thereof.

\section{New modes of modeling}

Simple models vs computational models.

What you gain and lose in both cases.

There are really three methods for comparing the Milky Way to
theoretical ideas. One is to use toys. One is to build MW analogs and
look at them with summary statistics. The most extreme is the
``constrained realization'' route, which sounds insane but has
successes (cite Peebles, Goldberg, Wang et al).  (Find a way to cite
Roth re modifying the initial conditions.)

\section{Data-driven methods}

There are (at least) three uses of what might be called ``machine learning''
in Galactic Archaeology right now. In the first, PCA and t-SNE are used to
find outliers or odd classes in data. These methods are successful and most
successful when applied directly to the data in as raw a form as possible, or
repeatedly at different stages in the pipeline. Cite!...

In the second, PCA and t-SNE are used to find stars with similar
abundances or common origin. These uses are illegitimate. There is no
way to force these methods---which capture variance, not
information---to respect our ideas about what's important in a stellar
spectrum or a set of abundance measurements. We should be building
models, not applying black-box methods....

In the third, the immense flexibility of machine-learning methods are
combined with things we know about instrument noise, instrument
resolution, and stellar physics to make models that are better than or
improve upon our best physics-based models of stars...

\section{Probabilistic thinking}

Pessimistic regime of chemical tagging; mixture models; hierarchical models.

ABC and better for simulation-based theory.

\end{document}
